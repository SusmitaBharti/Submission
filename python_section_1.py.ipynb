{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1gE4yaByZxKR-fTYRSeytBhJTW24Oonb8","timestamp":1729672315909}],"authorship_tag":"ABX9TyN1GHDncKhXkRKP0hugbMnV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RL2vKDboQqIR","executionInfo":{"status":"ok","timestamp":1729668975725,"user_tz":-330,"elapsed":6,"user":{"displayName":"Susmita","userId":"09438202502163888891"}},"outputId":"33212ecb-f416-44c2-cb7a-2c5e4e8d193a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input: [1, 2, 3, 4, 5, 6, 7, 8], n: 3\n","Output: [3, 2, 1, 6, 5, 4, 8, 7]\n","\n","Input: [1, 2, 3, 4, 5], n: 2\n","Output: [2, 1, 4, 3, 5]\n","\n","Input: [10, 20, 30, 40, 50, 60, 70], n: 4\n","Output: [40, 30, 20, 10, 70, 60, 50]\n","Input: [1, 2, 3, 4, 5, 6, 7, 8], n: 3\n","Output: [3, 2, 1, 6, 5, 4, 8, 7]\n","\n","Input: [1, 2, 3, 4, 5], n: 2\n","Output: [2, 1, 4, 3, 5]\n","\n","Input: [10, 20, 30, 40, 50, 60, 70], n: 4\n","Output: [40, 30, 20, 10, 70, 60, 50]\n"]}],"source":["def reverse_list_by_n(lst, n):\n","  reversed_lst = []\n","  for i in range(0, len(lst), n):\n","    group = lst[i:i + n]\n","    reversed_group = group[::-1]\n","    reversed_lst.extend(reversed_group)\n","\n","  return reversed_lst\n","\n","# Test cases\n","lst1 = [1, 2, 3, 4, 5, 6, 7, 8]\n","n1 = 3\n","print(f\"Input: {lst1}, n: {n1}\")\n","print(f\"Output: {reverse_list_by_n(lst1, n1)}\")\n","\n","lst2 = [1, 2, 3, 4, 5]\n","n2 = 2\n","print(f\"\\nInput: {lst2}, n: {n2}\")\n","print(f\"Output: {reverse_list_by_n(lst2, n2)}\")\n","\n","lst3 = [10, 20, 30, 40, 50, 60, 70]\n","n3 = 4\n","print(f\"\\nInput: {lst3}, n: {n3}\")\n","print(f\"Output: {reverse_list_by_n(lst3, n3)}\")"]},{"cell_type":"code","source":["def group_strings_by_length(strings):\n","  result = {}\n","  for string in strings:\n","    length = len(string)\n","    if length in result:\n","      result[length].append(string)\n","    else:\n","      result[length] = [string]\n","  return dict(sorted(result.items()))\n","\n","# Test cases\n","print(group_strings_by_length([\"apple\", \"bat\", \"car\", \"elephant\", \"dog\", \"bear\"]))\n","\n","print(group_strings_by_length([\"one\", \"two\", \"three\", \"four\"]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQNDPgFkTKuS","executionInfo":{"status":"ok","timestamp":1729669043749,"user_tz":-330,"elapsed":522,"user":{"displayName":"Susmita","userId":"09438202502163888891"}},"outputId":"1c30c785-0fe8-40db-e19a-ef7036cc97a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{3: ['bat', 'car', 'dog'], 4: ['bear'], 5: ['apple'], 8: ['elephant']}\n","{3: ['one', 'two'], 4: ['four'], 5: ['three']}\n"]}]},{"cell_type":"code","source":["def flatten_dictionary(dictionary):\n","    flattened = {}\n","\n","    def flatten(d, prefix=\"\"):\n","        for key, value in d.items():\n","            new_key = prefix + \".\" + key if prefix else key\n","            if isinstance(value, dict):\n","                flatten(value, new_key)\n","            elif isinstance(value, list):\n","                for i, item in enumerate(value):\n","                    flatten({str(i): item}, new_key)\n","            else:\n","                flattened[new_key] = value\n","\n","    flatten(dictionary)\n","    return flattened\n","\n","input_dictionary = {\n","    \"road\": {\n","        \"name\": \"Highway 1\",\n","        \"length\": 350,\n","        \"sections\": [\n","            {\"id\": 1, \"condition\": 1},\n","            {\"id\": 2, \"condition\": 2}\n","        ]\n","    }\n","}\n","\n","flattened_dictionary = flatten_dictionary(input_dictionary)\n","print(flattened_dictionary)"],"metadata":{"id":"JWYLvksXT6iY","executionInfo":{"status":"ok","timestamp":1729669115941,"user_tz":-330,"elapsed":518,"user":{"displayName":"Susmita","userId":"09438202502163888891"}},"outputId":"09615a1f-466a-4e46-8ff3-4973d9b17a35","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'road.name': 'Highway 1', 'road.length': 350, 'road.sections.0.id': 1, 'road.sections.0.condition': 1, 'road.sections.1.id': 2, 'road.sections.1.condition': 2}\n"]}]},{"cell_type":"code","source":["def generate_unique_permutations(nums):\n","  result = []\n","  def backtrack(index, current):\n","    if index == len(nums):\n","      result.append(current.copy())\n","      return\n","\n","    seen = set()\n","    for i in range(len(nums)):\n","      if nums[i] not in seen:\n","        seen.add(nums[i])\n","        current.append(nums[i])\n","        backtrack(index + 1, current)\n","        current.pop()\n","  backtrack(0, [])\n","  return result\n","nums = [1, 1, 2]\n","unique_permutations = generate_unique_permutations(nums)\n","print(unique_permutations)"],"metadata":{"id":"kJ7JX0rLUKGD","executionInfo":{"status":"ok","timestamp":1729669349953,"user_tz":-330,"elapsed":9,"user":{"displayName":"Susmita","userId":"09438202502163888891"}},"outputId":"eedfb42b-831e-44ab-869f-1fe3e86429d0","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1, 1, 1], [1, 1, 2], [1, 2, 1], [1, 2, 2], [2, 1, 1], [2, 1, 2], [2, 2, 1], [2, 2, 2]]\n"]}]},{"cell_type":"code","source":["import re\n","\n","def find_all_dates(text):\n","\n","  date_regex = r'\\d{2}-\\d{2}-\\d{4}|\\d{2}/\\d{2}/\\d{4}|\\d{4}\\.\\d{2}\\.\\d{2}'\n","  dates = re.findall(date_regex, text)\n","  return dates\n","\n","text = \"I was born on 23-08-1994, my friend on 08/23/1994, and another one on 1994.08.23.\"\n","dates = find_all_dates(text)\n","print(dates) # Output: ['23-08-1994', '08/23/1994', '1994.08.23']"],"metadata":{"id":"AZM2m3GRU_f9","executionInfo":{"status":"ok","timestamp":1729669803651,"user_tz":-330,"elapsed":446,"user":{"displayName":"Susmita","userId":"09438202502163888891"}},"outputId":"e577430b-496c-4a65-af9a-6eec1414d1d0","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['23-08-1994', '08/23/1994', '1994.08.23']\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import polyline\n","from geopy.distance import geodesic\n","\n","def decode_polyline_to_dataframe(polyline_str):\n","    # Step 1: Decode the polyline string into a list of (latitude, longitude) coordinates\n","    coordinates = polyline.decode(polyline_str)\n","\n","    # Step 2: Create a Pandas DataFrame with latitude and longitude\n","    df = pd.DataFrame(coordinates, columns=['latitude', 'longitude'])\n","\n","    # Step 3: Initialize the distance column with the first value as 0\n","    distances = [0.0]\n","\n","    # Step 4: Calculate distances between consecutive points using the Haversine formula\n","    for i in range(1, len(coordinates)):\n","        point1 = (df.iloc[i-1]['latitude'], df.iloc[i-1]['longitude'])\n","        point2 = (df.iloc[i]['latitude'], df.iloc[i]['longitude'])\n","        distance = geodesic(point1, point2).meters  # Calculate the distance in meters\n","        distances.append(distance)\n","\n","    # Step 5: Add the distances column to the DataFrame\n","    df['distance'] = distances\n","\n","    return df\n","\n","# Example usage\n","polyline_str = \"your_polyline_string_here\"  # Replace with actual polyline string\n","df = decode_polyline_to_dataframe(polyline_str)\n","print(df)"],"metadata":{"id":"4aFUMsa6Wu6Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def matrix_transformation(matrix):\n","  n = len(matrix)\n","  # Rotate the matrix 90 degrees clockwise\n","  rotated_matrix = [[0 for _ in range(n)] for _ in range(n)]\n","  for i in range(n):\n","    for j in range(n):\n","      rotated_matrix[j][n-i-1] = matrix[i][j]\n","\n","  # Replace each element with the sum of all elements in the same row and column, excluding itself\n","  final_matrix = [[0 for _ in range(n)] for _ in range(n)]\n","  for i in range(n):\n","    for j in range(n):\n","      row_sum = sum(rotated_matrix[i]) - rotated_matrix[i][j]\n","      col_sum = sum([rotated_matrix[k][j] for k in range(n)]) - rotated_matrix[i][j]\n","      final_matrix[i][j] = row_sum + col_sum\n","\n","  return final_matrix\n","\n","# Example usage:\n","matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n","transformed_matrix = matrix_transformation(matrix)\n","print(transformed_matrix)"],"metadata":{"id":"Im88d2D2aoPs","executionInfo":{"status":"ok","timestamp":1729671199081,"user_tz":-330,"elapsed":645,"user":{"displayName":"Susmita","userId":"09438202502163888891"}},"outputId":"45dbec01-984c-4329-b97e-04167026ad6a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[22, 19, 16], [23, 20, 17], [24, 21, 18]]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","def time_check(df):\n","\n","  df['startDateTime'] = pd.to_datetime(df['startDay'].astype(str) + ' ' + df['startTime'].astype(str))\n","  df['endDateTime'] = pd.to_datetime(df['endDay'].astype(str) + ' ' + df['endTime'].astype(str))\n","\n","  df = df.sort_values(by=['id', 'id_2', 'startDateTime'])\n","\n","  # Create a groupby object to group by id and id_2.\n","  gb = df.groupby(['id', 'id_2'])\n","\n","  # Apply a lambda function to each group to check for incorrect timestamps.\n","  result = gb.apply(lambda x: check_timestamps(x))\n","\n","  return result\n","\n","def check_timestamps(group):\n","  if not (group['startDateTime'].shift() == group['endDateTime']).all():\n","    return False\n","  if not (group['endDateTime'].iloc[-1] - group['startDateTime'].iloc[0] == pd.Timedelta(days=1)).all():\n","    return False\n","\n","  # Check if the timestamps span all 7 days of the week.\n","  if not (group['startDateTime'].dt.dayofweek):"],"metadata":{"id":"9E-0DP7PdNvR","executionInfo":{"status":"error","timestamp":1729671549884,"user_tz":-330,"elapsed":490,"user":{"displayName":"Susmita","userId":"09438202502163888891"}},"outputId":"eb40ad24-2ec3-46a4-c305-ccf3ead7f06e","colab":{"base_uri":"https://localhost:8080/","height":356}},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'dataset-1.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-5f66ee279c3a>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset-1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Check timestamps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset-1.csv'"]}]}]}